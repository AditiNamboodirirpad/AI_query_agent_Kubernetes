# AI Query Agent for Kubernetes

## Overview
This project implements an AI-powered agent using FastAPI that interacts with a Kubernetes cluster to answer queries about deployments, pods, nodes, and logs.  
It integrates the OpenAI API for natural language processing and the Kubernetes Python client for cluster operations.  

---

## Technologies
- **Python 3.10**: Programming language for the implementation.
- **FastAPI**: Framework for building the web application.
- **OpenAI API**: For natural language processing.
- **Kubernetes Client**: For interacting with the Kubernetes API.
- **Docker & Minikube**: For containerization and local Kubernetes deployment.

---

## Setup and Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/AI_query_agent_Kubernetes.git
cd AI_query_agent_Kubernetes
```

### 2. Install Dependencies (for local testing)
```bash
pip install -r requirements.txt
```
Dependencies include FastAPI, Uvicorn, OpenAI, Kubernetes, and python-dotenv.

### 3. Configure Environment Variables
Create a `.env` file in the project root:
```env
OPENAI_API_KEY=your_openai_api_key_here
```

---

## Dockerization

A `Dockerfile` is provided to containerize the application.  

1. Start Minikube:
```bash
minikube start --driver=docker
```

2. Point Docker to Minikube’s environment:
```bash
eval $(minikube docker-env)
```

3. Build the image:
```bash
docker build -t kubernetes-agent:latest .
```

4. Verify the image exists:
```bash
docker images
```

---

## Kubernetes Deployment

1. Create a Kubernetes Secret for the OpenAI API key:
```bash
kubectl create secret generic openai-secret   --from-literal=OPENAI_API_KEY="your_openai_api_key_here"
```

2. Apply the Deployment and Service:
```bash
kubectl apply -f deployment.yaml
```

3. Check resources:
```bash
kubectl get deployments
kubectl get pods
kubectl get svc
```

The `deployment.yaml` defines:  
- A Deployment (`aditi-agent-deployment`) with one replica of the FastAPI agent.  
- A Service (`aditi-agent-service`) exposing port 8000 via NodePort.  

---

## Accessing the Service

Expose the service with Minikube:
```bash
minikube service aditi-agent-service
```

This opens the FastAPI app in your browser at a tunneled localhost port, for example:  
`http://127.0.0.1:53716/docs`  

Swagger UI (`/docs`) is auto-generated by FastAPI and can be used to test queries interactively.  

---

## Testing

Deploy a sample nginx workload to test the agent:
```bash
kubectl create deployment aditi-first-deployment --image=nginx --replicas=5
```

Example queries in Swagger UI:
```json
{ "query": "How many pods are running in the default namespace?" }
{ "query": "Give me the names of the pods in default namespace" }
{ "query": "What deployments are running in default namespace?" }
{ "query": "Show me the log for the pod <pod-name> in the default namespace" }
```

---

## Code Workflow

### Imports
- Imported necessary libraries such as FastAPI (for the API framework), logging (for monitoring), Pydantic (for data validation), and the Kubernetes Python client (for API interaction).  
- Additional imports include dotenv (for environment variables) and the OpenAI client (for natural language answers).  

### Environment Variables
- Loaded environment variables from a `.env` file to securely retrieve the OpenAI API key.  
- Initialized the AsyncOpenAI client with this key for querying the OpenAI API.  

### FastAPI Application
- Initialized a FastAPI application instance to act as the web server that handles requests and responses.  

### Data Models
Defined request and response models using Pydantic:  
- `QueryRequest`: validates incoming requests containing a `query` string.  
- `QueryResponse`: formats the outgoing response with both the original `query` and the generated `answer`.  

### Kubernetes API Interactions
Developed helper functions to interact with the Kubernetes cluster:  
- `get_pods_info`: Fetches information about all pods in a specified namespace.  
- `get_deployments_info`: Retrieves deployment information.  
- `get_pod_logs`: Fetches logs from a specified pod.  
- `get_nodes_info`: Provides details about each node in the cluster, including status, labels, and availability.  

### API Endpoint
Created a POST endpoint (`/query`) to handle incoming queries:  
- Logs the received query for debugging.  
- Determines if the query is about pod logs or general Kubernetes resources.  
- Fetches relevant Kubernetes data (pods, deployments, nodes).  
- Constructs a prompt that combines this data with the user’s query.  
- Uses the OpenAI API to generate a natural language answer.  
- Returns the answer formatted as a `QueryResponse`.  

### Error Handling
- Implemented try/except blocks to catch errors during Kubernetes API calls.  
- Logs all exceptions for troubleshooting.  
- Returns an appropriate `HTTPException` when issues occur (e.g., missing pods or invalid queries).  

### Application Execution
- The entry point runs the FastAPI application using Uvicorn:
  ```python
  if __name__ == "__main__":
      uvicorn.run(app, host="0.0.0.0", port=8000)
  ```
- Locally (without Docker): run with `uvicorn main:app --reload` to quickly test code changes before building the Docker image.  
- Inside Kubernetes: the Dockerized container runs Uvicorn automatically when the pod starts.  

---

## Conclusion
This project demonstrates the integration of FastAPI, Docker, Kubernetes, and OpenAI into a functional agent capable of answering natural language queries about cluster resources.  
It can be extended for more complex use cases, making it a foundation for intelligent Kubernetes assistants.  
